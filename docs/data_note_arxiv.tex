\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{siunitx}

\title{BeepBank-500: A Synthetic Earcon Mini-Corpus for UI Sound Research}
\author{Mandip Goswami}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
We introduce \textbf{BeepBank-500}, a compact, fully synthetic earcon/alert dataset (300--500 clips) designed for rapid, rights-clean experimentation in human-computer interaction and audio machine learning. Each clip is generated from a parametric recipe controlling waveform family (sine, square, triangle, FM), fundamental frequency, duration, amplitude envelope, amplitude modulation, and simple Schroeder-style reverberation. We release audio (mono, 48~kHz, 16-bit), a rich metadata table (signal and spectral features), and tiny reproducible baselines for waveform classification and $f_0$ regression. The dataset is intended for tasks such as earcon classification, timbre similarity analyses, and onset detection benchmarks. Audio is released under CC0-1.0, code under MIT. Data and code: \href{https://doi.org/10.5281/zenodo.XXXXXXX}{Zenodo DOI (to be added)}; GitHub: \url{https://github.com/<your-username>/earcons-mini-500}.
\end{abstract}


\section{Availability}
Zenodo DOI: \url{https://doi.org/10.5281/zenodo.17172015} \\
GitHub: \url{https://github.com/mandip42/earcons-mini-500}.

\end{document}
